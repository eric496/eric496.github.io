---
layout: post
title: Machine Learning Week 1 Note
categories: notes
---
### What is machine learning
[Tom Mitchell](http://www.cs.cmu.edu/~tom/)'s definition:

> A computer program is said to learn from **experience** E with respect to some class of **tasks** T and **performance** measure P, if its performance at tasks in T, as measured by P, improves with experience E.

### Types of Machine Learning
1. **Supervised Learning**: machine learning task of inferring a function from *labeled* training data
  * Regression
  * Classification
2. **Unsupervised Learning**: machine learning task of inferring a function to describe hidden structure from *unlabeled* data
  * Clustering
3. **Reinforcement Learning**: machine learning task of training *agents* to take *actions* in an environment in order to maximize the *reward*

### Model Representation
1. Some notations:
  * $$(x^{(i)}, y^{(i)})$$ represents the $$i^{th}$$ training data point
  * $$x_i$$ represents the $$i^{th}$$ feature
  * $$\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ... , (x^{(m)}, y^{(m)})\}$$ represents the training set

2. Training set -> Learning algorithm -> Hypothesis
* X -> $$h(x)$$ -> Y
3. How do we represent $$h(x)$$?
* We can pick various models, for example, the univariate linear regression $$h_{\theta}(x) = {\theta}_{0} + {\theta}_{1}x$$

### Cost Function
1. Hypothesis: $$h_{\theta}(X) = {\theta}_{0} + {\theta}_{1}X$$
* $$\bf{\theta} = \begin{bmatrix}{\theta}_{0} \\ {\theta}_{1}\end{bmatrix}$$ is called the parameters
2. Idea: choose $$\bf{\theta}$$ so that $$h_{\theta}(x)$$ is close to $$y$$ for $$\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ... , (x^{(m)}, y^{(m)})\}$$
3. Cost function is defined as:
